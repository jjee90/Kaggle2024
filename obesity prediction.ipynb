{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20758 entries, 0 to 20757\n",
      "Data columns (total 18 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              20758 non-null  int64  \n",
      " 1   Gender                          20758 non-null  object \n",
      " 2   Age                             20758 non-null  float64\n",
      " 3   Height                          20758 non-null  float64\n",
      " 4   Weight                          20758 non-null  float64\n",
      " 5   family_history_with_overweight  20758 non-null  object \n",
      " 6   FAVC                            20758 non-null  object \n",
      " 7   FCVC                            20758 non-null  float64\n",
      " 8   NCP                             20758 non-null  float64\n",
      " 9   CAEC                            20758 non-null  object \n",
      " 10  SMOKE                           20758 non-null  object \n",
      " 11  CH2O                            20758 non-null  float64\n",
      " 12  SCC                             20758 non-null  object \n",
      " 13  FAF                             20758 non-null  float64\n",
      " 14  TUE                             20758 non-null  float64\n",
      " 15  CALC                            20758 non-null  object \n",
      " 16  MTRANS                          20758 non-null  object \n",
      " 17  NObeyesdad                      20758 non-null  object \n",
      "dtypes: float64(8), int64(1), object(9)\n",
      "memory usage: 2.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>no</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>no</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>no</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "0   0    Male  24.443011  1.699998   81.669950                            yes   \n",
       "1   1  Female  18.000000  1.560000   57.000000                            yes   \n",
       "2   2  Female  18.000000  1.711460   50.165754                            yes   \n",
       "3   3  Female  20.952737  1.710730  131.274851                            yes   \n",
       "4   4    Male  31.641081  1.914186   93.798055                            yes   \n",
       "\n",
       "  FAVC      FCVC       NCP        CAEC SMOKE      CH2O SCC       FAF  \\\n",
       "0  yes  2.000000  2.983297   Sometimes    no  2.763573  no  0.000000   \n",
       "1  yes  2.000000  3.000000  Frequently    no  2.000000  no  1.000000   \n",
       "2  yes  1.880534  1.411685   Sometimes    no  1.910378  no  0.866045   \n",
       "3  yes  3.000000  3.000000   Sometimes    no  1.674061  no  1.467863   \n",
       "4  yes  2.679664  1.971472   Sometimes    no  1.979848  no  1.967973   \n",
       "\n",
       "        TUE       CALC                 MTRANS           NObeyesdad  \n",
       "0  0.976473  Sometimes  Public_Transportation  Overweight_Level_II  \n",
       "1  1.000000         no             Automobile        Normal_Weight  \n",
       "2  1.673584         no  Public_Transportation  Insufficient_Weight  \n",
       "3  0.780199  Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "4  0.931721  Sometimes  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "train.info()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "\n",
    "## Gender to binary\n",
    "train['Gender'] = train['Gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "## family_history_with_overweight to binary\n",
    "train['family_history_with_overweight'] = train['family_history_with_overweight'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "## FAVC to binary\n",
    "train['FAVC'] = train['FAVC'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "## CAEC to ordinal\n",
    "train['CAEC'] = train['CAEC'].map({'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3})\n",
    "\n",
    "## SMOKE to binary\n",
    "train['SMOKE'] = train['SMOKE'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "## SCC to binary\n",
    "train['SCC'] = train['SCC'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "## CALC to ordinal\n",
    "train['CALC'] = train['CALC'].map({'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3})\n",
    "\n",
    "## MTRANS to ordinal\n",
    "train['MTRANS'] = train['MTRANS'].map({'Public_Transportation': 0, 'Automobile': 1, 'Motorbike': 2, 'Bike': 3, 'Walking': 4})\n",
    "\n",
    "## NObeyesdad to ordinal\n",
    "train['NObeyesdad'] = train['NObeyesdad'].map({'Insufficient_Weight': 0, 'Normal_Weight': 1, 'Overweight_Level_I': 2, 'Overweight_Level_II': 3, 'Obesity_Type_I': 4, 'Obesity_Type_II': 5, 'Obesity_Type_III': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data into features and target variable\n",
    "X = train.drop('NObeyesdad', axis=1)\n",
    "y = train['NObeyesdad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "\n",
    "## Gender to binary\n",
    "test['Gender'] = test['Gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "## family_history_with_overweight to binary\n",
    "test['family_history_with_overweight'] = test['family_history_with_overweight'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "## FAVC to binary\n",
    "test['FAVC'] = test['FAVC'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "## CAEC to ordinal\n",
    "test['CAEC'] = test['CAEC'].map({'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3})\n",
    "\n",
    "## SMOKE to binary\n",
    "test['SMOKE'] = test['SMOKE'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "## SCC to binary\n",
    "test['SCC'] = test['SCC'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "## CALC to ordinal\n",
    "test['CALC'] = test['CALC'].map({'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3})\n",
    "\n",
    "## MTRANS to ordinal\n",
    "test['MTRANS'] = test['MTRANS'].map({'Public_Transportation': 0, 'Automobile': 1, 'Motorbike': 2, 'Bike': 3, 'Walking': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "# 0.2 test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 0.3 test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20758 entries, 0 to 20757\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              20758 non-null  int64  \n",
      " 1   Gender                          20758 non-null  int64  \n",
      " 2   Age                             20758 non-null  float64\n",
      " 3   Height                          20758 non-null  float64\n",
      " 4   Weight                          20758 non-null  float64\n",
      " 5   family_history_with_overweight  20758 non-null  int64  \n",
      " 6   FAVC                            20758 non-null  int64  \n",
      " 7   FCVC                            20758 non-null  float64\n",
      " 8   NCP                             20758 non-null  float64\n",
      " 9   CAEC                            20758 non-null  int64  \n",
      " 10  SMOKE                           20758 non-null  int64  \n",
      " 11  CH2O                            20758 non-null  float64\n",
      " 12  SCC                             20758 non-null  int64  \n",
      " 13  FAF                             20758 non-null  float64\n",
      " 14  TUE                             20758 non-null  float64\n",
      " 15  CALC                            20758 non-null  int64  \n",
      " 16  MTRANS                          20758 non-null  int64  \n",
      "dtypes: float64(8), int64(9)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_st = X.copy()\n",
    "\n",
    "# convert column types from object to numeric\n",
    "X_st = X_st.apply(pd.to_numeric, errors='coerce')\n",
    "X_st.info()\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_st = scaler.fit_transform(X_st)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train_st, X_test_st, y_train_st, y_test_st = train_test_split(X_st, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "- 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36801541425818884\n",
      "Confusion Matrix:\n",
      " [[223 233   0  51  17   0   0]\n",
      " [ 97 284   0 108 112  18   7]\n",
      " [ 56 129   1  46 130  69  53]\n",
      " [ 59  99   0  79 123  82  72]\n",
      " [ 52  24   0  39  96 125 207]\n",
      " [  1   3   0  38  71 273 271]\n",
      " [  0   0   0   0   1 231 572]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.43      0.44       524\n",
      "           1       0.37      0.45      0.41       626\n",
      "           2       1.00      0.00      0.00       484\n",
      "           3       0.22      0.15      0.18       514\n",
      "           4       0.17      0.18      0.18       543\n",
      "           5       0.34      0.42      0.38       657\n",
      "           6       0.48      0.71      0.58       804\n",
      "\n",
      "    accuracy                           0.37      4152\n",
      "   macro avg       0.43      0.33      0.31      4152\n",
      "weighted avg       0.43      0.37      0.33      4152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create and train logistic regression model\n",
    "lreg = LogisticRegression(max_iter=1000)\n",
    "lreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lreg.predict(X_test)\n",
    "\n",
    "# Evaluate the lreg\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36801541425818884\n",
      "[[223 233   0  51  17   0   0]\n",
      " [ 97 284   0 108 112  18   7]\n",
      " [ 56 129   1  46 130  69  53]\n",
      " [ 59  99   0  79 123  82  72]\n",
      " [ 52  24   0  39  96 125 207]\n",
      " [  1   3   0  38  71 273 271]\n",
      " [  0   0   0   0   1 231 572]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.43      0.44       524\n",
      "           1       0.37      0.45      0.41       626\n",
      "           2       1.00      0.00      0.00       484\n",
      "           3       0.22      0.15      0.18       514\n",
      "           4       0.17      0.18      0.18       543\n",
      "           5       0.34      0.42      0.38       657\n",
      "           6       0.48      0.71      0.58       804\n",
      "\n",
      "    accuracy                           0.37      4152\n",
      "   macro avg       0.43      0.33      0.31      4152\n",
      "weighted avg       0.43      0.37      0.33      4152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# with multi class\n",
    "\n",
    "# create a logistic regression model\n",
    "lreg2 = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "\n",
    "# fit the lreg2 to the training data\n",
    "lreg2.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = lreg2.predict(X_test)  \n",
    "\n",
    "# print the accuracy score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with or without the multinomial, the result is the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper tuning: the best max_iter value based on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_iter = [100, 1000, 2000, 5000, 10000]\n",
    "accuracy = []\n",
    "\n",
    "for i in max_iter:\n",
    "    lreg = LogisticRegression(max_iter=i)\n",
    "    lreg.fit(X_train, y_train)\n",
    "    y_pred = lreg.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "plt.plot(max_iter, accuracy)\n",
    "plt.xlabel('max_iter')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('max_iter vs accuracy')\n",
    "plt.show()\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With approximately 10,000 its accuracy reached to the top (about 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper tuning: the best solver with 10,000 max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for i in solvers:\n",
    "    lreg = LogisticRegression(max_iter=10000, solver=i)\n",
    "    lreg.fit(X_train, y_train)\n",
    "    y_pred = lreg.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "plt.plot(solvers, accuracy)\n",
    "plt.xlabel('solvers')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('solvers vs accuracy')\n",
    "plt.show()\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 5 solvers, with about 85% accuracy, newton-cg is the best solver and it's better than default solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "- 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8473025048169557\n",
      "Confusion Matrix:\n",
      " [[463  55   3   2   1   0   0]\n",
      " [ 55 484  78   8   1   0   0]\n",
      " [  1  52 341  73  15   1   1]\n",
      " [  0  14  77 369  46   8   0]\n",
      " [  2   1  28  55 440  16   1]\n",
      " [  0   0   0   4  33 619   1]\n",
      " [  0   0   0   0   1   1 802]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       524\n",
      "           1       0.80      0.77      0.79       626\n",
      "           2       0.65      0.70      0.67       484\n",
      "           3       0.72      0.72      0.72       514\n",
      "           4       0.82      0.81      0.81       543\n",
      "           5       0.96      0.94      0.95       657\n",
      "           6       1.00      1.00      1.00       804\n",
      "\n",
      "    accuracy                           0.85      4152\n",
      "   macro avg       0.83      0.83      0.83      4152\n",
      "weighted avg       0.85      0.85      0.85      4152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train decision tree tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree with no hyper tuning is about 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper tuning: the best depth value based on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7160404624277457, 0.8369460500963392, 0.8684971098265896, 0.8538053949903661, 0.8458574181117534]\n"
     ]
    }
   ],
   "source": [
    "max_depth = [3, 5, 10, 15, 20]\n",
    "accuracy = []\n",
    "\n",
    "for i in max_depth:\n",
    "    dt = DecisionTreeClassifier(max_depth=i)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "plt.plot(max_depth, accuracy)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('max_depth vs accuracy')\n",
    "plt.show()\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the max depth of 10, its accuracy is the highest (about 87%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "- 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9007707129094412\n",
      "Confusion Matrix:\n",
      " [[486  35   2   1   0   0   0]\n",
      " [ 27 555  38   6   0   0   0]\n",
      " [  1  49 371  55   8   0   0]\n",
      " [  0  13  48 412  36   5   0]\n",
      " [  2   2  14  40 474  10   1]\n",
      " [  0   0   0   2  15 640   0]\n",
      " [  0   0   0   0   1   1 802]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       524\n",
      "           1       0.85      0.89      0.87       626\n",
      "           2       0.78      0.77      0.78       484\n",
      "           3       0.80      0.80      0.80       514\n",
      "           4       0.89      0.87      0.88       543\n",
      "           5       0.98      0.97      0.97       657\n",
      "           6       1.00      1.00      1.00       804\n",
      "\n",
      "    accuracy                           0.90      4152\n",
      "   macro avg       0.89      0.89      0.89      4152\n",
      "weighted avg       0.90      0.90      0.90      4152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, rf_y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Tuning: the best n_estimators for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8783718689788054, 0.899325626204239, 0.896917148362235, 0.8954720616570327, 0.8983622350674374]\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 50, 100, 200, 500]\n",
    "accuracy = []\n",
    "\n",
    "for i in n_estimators:\n",
    "    rf = RandomForestClassifier(n_estimators=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_y_pred = rf.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, rf_y_pred))\n",
    "\n",
    "plt.plot(n_estimators, accuracy)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('n_estimators vs accuracy')\n",
    "plt.show()\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any hyper tuning, the general random forest has the highest accuracy with 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "- 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5250481695568401\n",
      "Confusion Matrix:\n",
      " [[217  93  16  25  89  65  19]\n",
      " [125 161  53  34 137  73  43]\n",
      " [ 78  50 103  12  89 124  28]\n",
      " [ 28  29  13  76 185 165  18]\n",
      " [  5   9  30  16 331 106  46]\n",
      " [  0   3   0  13 147 494   0]\n",
      " [  1   1   3   0   0   1 798]]\n",
      "Accuracy: 0.697495183044316\n",
      "Confusion Matrix:\n",
      " [[430  90   1   0   3   0   0]\n",
      " [168 343  61  20  24   0  10]\n",
      " [  8  89 176  60 141   0  10]\n",
      " [  1  41  34 163 256  17   2]\n",
      " [  2   1  20  40 377  97   6]\n",
      " [  0   0   1   5  46 605   0]\n",
      " [  0   0   1   0   0   1 802]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "\n",
    "NB = BernoulliNB()\n",
    "NB.fit(X_train, np.ravel(y_train))\n",
    "NB_pred = NB.predict(X_test)\n",
    "\n",
    "GAUSSmodel = GaussianNB()\n",
    "GAUSSmodel.fit(X_train, np.ravel(y_train))\n",
    "NGaussY_pred = GAUSSmodel.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, NB_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, NB_pred))\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, NGaussY_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, NGaussY_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB has higher accuracy with about 0.7 than BernoulliNB but its accuracy is lower than others above, and hyper tuning for the model was not successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **XGBoost**\n",
    "- 91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       755\n",
      "           1       0.86      0.89      0.88       907\n",
      "           2       0.78      0.80      0.79       733\n",
      "           3       0.80      0.78      0.79       763\n",
      "           4       0.88      0.87      0.87       858\n",
      "           5       0.97      0.98      0.97      1005\n",
      "           6       0.99      1.00      1.00      1207\n",
      "\n",
      "    accuracy                           0.90      6228\n",
      "   macro avg       0.89      0.89      0.89      6228\n",
      "weighted avg       0.90      0.90      0.90      6228\n",
      "\n",
      "XGBoost Confusion Matrix: [[ 683   66    3    2    1    0    0]\n",
      " [  34  807   56   10    0    0    0]\n",
      " [   3   45  587   81   17    0    0]\n",
      " [   0   16   79  593   67    8    0]\n",
      " [   2    1   28   57  743   24    3]\n",
      " [   0    0    0    2   19  980    4]\n",
      " [   1    0    1    0    0    1 1204]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Algorithm\n",
    "# !pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# XGBoost Model\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"XGBoost Classification Report:\", classification_report(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Confusion Matrix:\", confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost has quite higher accuracy (90%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper tuning xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "grid_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Classification Report:\", classification_report(y_test, grid_pred))\n",
    "print(\"XGBoost Confusion Matrix:\", confusion_matrix(y_test, grid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 50}\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.3, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=50,\n",
      "              n_jobs=None, num_parallel_tree=None, objective='multi:softprob', ...)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       524\n",
      "           1       0.87      0.90      0.89       626\n",
      "           2       0.79      0.78      0.78       484\n",
      "           3       0.80      0.82      0.81       514\n",
      "           4       0.90      0.87      0.89       543\n",
      "           5       0.97      0.98      0.97       657\n",
      "           6       1.00      1.00      1.00       804\n",
      "\n",
      "    accuracy                           0.91      4152\n",
      "   macro avg       0.90      0.90      0.90      4152\n",
      "weighted avg       0.91      0.91      0.91      4152\n",
      "\n",
      "XGBoost Confusion Matrix: [[489  32   2   1   0   0   0]\n",
      " [ 24 562  35   5   0   0   0]\n",
      " [  1  41 376  58   8   0   0]\n",
      " [  0   8  48 421  33   4   0]\n",
      " [  2   0  14  39 473  14   1]\n",
      " [  0   0   0   3  10 641   3]\n",
      " [  0   0   0   1   0   1 802]]\n"
     ]
    }
   ],
   "source": [
    "# xgboost with the best parameters\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', learning_rate=0.05, max_depth=5, n_estimators=200)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"XGBoost Classification Report:\", classification_report(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Confusion Matrix:\", confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the best parameters(eval_metric='logloss', learning_rate=0.05, max_depth=5, n_estimators=200), the accuracy is 91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=10;, score=0.801 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=10;, score=0.831 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=10;, score=0.793 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=10;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=10;, score=0.812 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=50;, score=0.835 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=50;, score=0.845 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=50;, score=0.847 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=50;, score=0.838 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=50;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.866 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.873 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.875 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.863 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=100;, score=0.889 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=200;, score=0.893 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=200;, score=0.893 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=200;, score=0.896 total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=200;, score=0.889 total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=200;, score=0.911 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=10;, score=0.859 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=10;, score=0.870 total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=10;, score=0.867 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=10;, score=0.856 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=10;, score=0.884 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=50;, score=0.877 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=50;, score=0.887 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=50;, score=0.880 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=50;, score=0.876 total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=50;, score=0.903 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=100;, score=0.888 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=100;, score=0.899 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=100;, score=0.893 total time=   4.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=100;, score=0.893 total time=   3.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=100;, score=0.913 total time=   2.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=200;, score=0.899 total time=   7.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=200;, score=0.907 total time=   5.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=200;, score=0.896 total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=200;, score=0.902 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=200;, score=0.917 total time=   2.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=10, n_estimators=10;, score=0.880 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=10, n_estimators=10;, score=0.893 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=10, n_estimators=10;, score=0.895 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=10, n_estimators=10;, score=0.882 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=10, n_estimators=10;, score=0.908 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=10, n_estimators=50;, score=0.887 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=10, n_estimators=50;, score=0.897 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=10, n_estimators=50;, score=0.896 total time=   2.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=10, n_estimators=50;, score=0.892 total time=   2.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=10, n_estimators=50;, score=0.909 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=10, n_estimators=100;, score=0.891 total time=   5.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=10, n_estimators=100;, score=0.902 total time=   5.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=10, n_estimators=100;, score=0.896 total time=   5.3s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=10, n_estimators=100;, score=0.896 total time=   4.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=10, n_estimators=100;, score=0.912 total time=   4.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=10, n_estimators=200;, score=0.895 total time=   8.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=10, n_estimators=200;, score=0.904 total time=   8.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=10, n_estimators=200;, score=0.898 total time=   9.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=10, n_estimators=200;, score=0.895 total time=   6.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=10, n_estimators=200;, score=0.911 total time=   7.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=0.821 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=0.818 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=10;, score=0.815 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.866 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.872 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.876 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.865 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.889 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.891 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.894 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.897 total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.890 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.912 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.899 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.905 total time=   2.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.904 total time=   2.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.902 total time=   2.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.918 total time=   3.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=0.864 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=0.876 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=0.870 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=0.862 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=10;, score=0.889 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.889 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.899 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.896 total time=   1.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.890 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.912 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.896 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.908 total time=   1.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.901 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.902 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.917 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.900 total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.910 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.902 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.904 total time=   3.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.917 total time=   4.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=0.882 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=0.896 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=0.892 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=0.888 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=10;, score=0.905 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.892 total time=   1.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.903 total time=   3.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.894 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.898 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=50;, score=0.912 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.892 total time=   4.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.909 total time=   4.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.899 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.897 total time=   3.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=0.910 total time=   2.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.893 total time=   6.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.907 total time=   6.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.897 total time=   7.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.898 total time=   8.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.909 total time=  10.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=10;, score=0.826 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=10;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=10;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=10;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=10;, score=0.846 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=50;, score=0.891 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=50;, score=0.895 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=50;, score=0.896 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=50;, score=0.890 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=50;, score=0.914 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.900 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.907 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.902 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.904 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=0.918 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=0.899 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=0.904 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=0.905 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=0.908 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=0.918 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=10;, score=0.877 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=10;, score=0.886 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=10;, score=0.880 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=10;, score=0.872 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=10;, score=0.898 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=50;, score=0.896 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=50;, score=0.907 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=50;, score=0.902 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=50;, score=0.902 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=50;, score=0.919 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=0.899 total time=   1.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=0.909 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=0.903 total time=   1.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=0.902 total time=   1.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=0.915 total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=0.895 total time=   2.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=0.909 total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=0.899 total time=   2.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=0.901 total time=   2.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=0.917 total time=   2.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=10;, score=0.887 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=10;, score=0.895 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=10;, score=0.893 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=10;, score=0.891 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=10;, score=0.910 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=50;, score=0.892 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=50;, score=0.904 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=50;, score=0.900 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=50;, score=0.897 total time=   1.6s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=50;, score=0.908 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=0.893 total time=   2.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=0.903 total time=   2.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=0.898 total time=   2.7s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=0.898 total time=   3.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=0.910 total time=   2.8s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=200;, score=0.892 total time=   4.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=200;, score=0.905 total time=   4.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=200;, score=0.899 total time=   5.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=200;, score=0.899 total time=   7.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=200;, score=0.912 total time=   4.5s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, n_estimators=10;, score=0.849 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, n_estimators=10;, score=0.852 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, n_estimators=10;, score=0.851 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, n_estimators=10;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, n_estimators=10;, score=0.863 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.897 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.902 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.901 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.900 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.915 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, n_estimators=100;, score=0.899 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, n_estimators=100;, score=0.906 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, n_estimators=100;, score=0.906 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, n_estimators=100;, score=0.903 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, n_estimators=100;, score=0.918 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, n_estimators=200;, score=0.896 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, n_estimators=200;, score=0.903 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, n_estimators=200;, score=0.904 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, n_estimators=200;, score=0.907 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, n_estimators=200;, score=0.917 total time=   1.7s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=5, n_estimators=10;, score=0.881 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=5, n_estimators=10;, score=0.891 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=5, n_estimators=10;, score=0.885 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=5, n_estimators=10;, score=0.881 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=5, n_estimators=10;, score=0.900 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.902 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.908 total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.902 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.906 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.917 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=5, n_estimators=100;, score=0.896 total time=   1.3s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=5, n_estimators=100;, score=0.908 total time=   1.3s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=5, n_estimators=100;, score=0.901 total time=   1.6s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=5, n_estimators=100;, score=0.902 total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=5, n_estimators=100;, score=0.917 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=5, n_estimators=200;, score=0.895 total time=   3.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=5, n_estimators=200;, score=0.909 total time=   3.2s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=5, n_estimators=200;, score=0.900 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=5, n_estimators=200;, score=0.900 total time=   3.2s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=5, n_estimators=200;, score=0.915 total time=   2.7s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=10, n_estimators=10;, score=0.889 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=10, n_estimators=10;, score=0.900 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=10, n_estimators=10;, score=0.896 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=10, n_estimators=10;, score=0.896 total time=   0.5s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=10, n_estimators=10;, score=0.913 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=10, n_estimators=50;, score=0.896 total time=   1.7s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=10, n_estimators=50;, score=0.905 total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=10, n_estimators=50;, score=0.898 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=10, n_estimators=50;, score=0.898 total time=   3.6s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=10, n_estimators=50;, score=0.910 total time=   3.9s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=10, n_estimators=100;, score=0.893 total time=   7.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=10, n_estimators=100;, score=0.904 total time=   6.3s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=10, n_estimators=100;, score=0.899 total time=   4.8s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=10, n_estimators=100;, score=0.899 total time=   5.3s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=10, n_estimators=100;, score=0.910 total time=   2.8s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=10, n_estimators=200;, score=0.891 total time=   5.1s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=10, n_estimators=200;, score=0.903 total time=   6.4s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=10, n_estimators=200;, score=0.896 total time=   9.4s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=10, n_estimators=200;, score=0.902 total time=   9.3s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=10, n_estimators=200;, score=0.912 total time=   6.7s\n",
      "{'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 50}\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.3, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=50,\n",
      "              n_jobs=None, num_parallel_tree=None, objective='multi:softprob', ...)\n",
      "XGBoost Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       524\n",
      "           1       0.88      0.89      0.88       626\n",
      "           2       0.77      0.77      0.77       484\n",
      "           3       0.79      0.82      0.80       514\n",
      "           4       0.90      0.87      0.88       543\n",
      "           5       0.97      0.97      0.97       657\n",
      "           6       1.00      1.00      1.00       804\n",
      "\n",
      "    accuracy                           0.90      4152\n",
      "   macro avg       0.89      0.89      0.89      4152\n",
      "weighted avg       0.90      0.90      0.90      4152\n",
      "\n",
      "XGBoost Confusion Matrix: [[487  34   2   1   0   0   0]\n",
      " [ 24 555  40   7   0   0   0]\n",
      " [  1  37 374  62  10   0   0]\n",
      " [  0   7  52 419  31   5   0]\n",
      " [  2   0  17  39 473  11   1]\n",
      " [  0   0   0   2  13 640   2]\n",
      " [  0   0   1   0   0   1 802]]\n"
     ]
    }
   ],
   "source": [
    "# hyper tuning xgboost\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid, verbose=3)\n",
    "\n",
    "grid.fit(X_train_st, y_train_st)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "grid_pred_st = grid.predict(X_test_st)\n",
    "\n",
    "print(\"XGBoost Classification Report:\", classification_report(y_test_st, grid_pred_st))\n",
    "print(\"XGBoost Confusion Matrix:\", confusion_matrix(y_test_st, grid_pred_st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.919 with learning_rate=0.2, max_depth=5, n_estimators=50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       524\n",
      "           1       0.88      0.89      0.88       626\n",
      "           2       0.78      0.78      0.78       484\n",
      "           3       0.80      0.81      0.80       514\n",
      "           4       0.90      0.88      0.89       543\n",
      "           5       0.98      0.97      0.97       657\n",
      "           6       1.00      1.00      1.00       804\n",
      "\n",
      "    accuracy                           0.91      4152\n",
      "   macro avg       0.90      0.89      0.90      4152\n",
      "weighted avg       0.91      0.91      0.91      4152\n",
      "\n",
      "XGBoost Confusion Matrix: [[490  31   2   1   0   0   0]\n",
      " [ 24 557  39   6   0   0   0]\n",
      " [  1  40 376  58   9   0   0]\n",
      " [  0   8  52 417  33   4   0]\n",
      " [  2   0  13  38 478  11   1]\n",
      " [  0   0   0   3  11 640   3]\n",
      " [  0   0   0   1   0   1 802]]\n"
     ]
    }
   ],
   "source": [
    "# xgboost with the best parameters (standardized)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', learning_rate=0.2, max_depth=5, n_estimators=50)\n",
    "xgb.fit(X_train_st, y_train_st)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb_st = xgb.predict(X_test_st)\n",
    "\n",
    "# Evaluation\n",
    "print(\"XGBoost Classification Report:\", classification_report(y_test_st, y_pred_xgb_st))\n",
    "print(\"XGBoost Confusion Matrix:\", confusion_matrix(y_test_st, y_pred_xgb_st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result was the same, so stick to the xgboost model with the best parameters (standardized) with 0.2 test size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) ~Error~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flags' object has no attribute 'c_contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m y_pred_knn \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKNN Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m, classification_report(y_test, y_pred_knn))\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:246\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    244\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fit_method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ArgKminClassMode\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[0;32m    247\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\n\u001b[0;32m    248\u001b[0m     ):\n\u001b[0;32m    249\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_:\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:471\u001b[0m, in \u001b[0;36mArgKminClassMode.is_usable_for\u001b[1;34m(cls, X, Y, metric)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_usable_for\u001b[39m(\u001b[38;5;28mcls\u001b[39m, X, Y, metric) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the dispatcher can be used for the given parameters.\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m    True if the PairwiseDistancesReduction can be used, else False.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 471\u001b[0m         ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(X, Y, metric)\n\u001b[0;32m    472\u001b[0m         \u001b[38;5;66;03m# TODO: Support CSR matrices.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(X)\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(Y)\n\u001b[0;32m    475\u001b[0m         \u001b[38;5;66;03m# TODO: implement Euclidean specialization with GEMM.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqeuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    477\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:115\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for\u001b[1;34m(cls, X, Y, metric)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_sparse_matrix\u001b[39m(X):\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    103\u001b[0m         isspmatrix_csr(X)\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m         X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mint32\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    113\u001b[0m is_usable \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    114\u001b[0m     get_config()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_cython_pairwise_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (is_numpy_c_ordered(X) \u001b[38;5;129;01mor\u001b[39;00m is_valid_sparse_matrix(X))\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (is_numpy_c_ordered(Y) \u001b[38;5;129;01mor\u001b[39;00m is_valid_sparse_matrix(Y))\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mfloat32, np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_metrics()\n\u001b[0;32m    120\u001b[0m )\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_usable\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:99\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for.<locals>.is_numpy_c_ordered\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_numpy_c_ordered\u001b[39m(X):\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflags\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Flags' object has no attribute 'c_contiguous'"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN) Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# KNN Model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"KNN Classification Report:\", classification_report(y_test, y_pred_knn))\n",
    "print(\"KNN Confusion Matrix:\", confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flags' object has no attribute 'c_contiguous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m y_pred_knn \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKNN Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m, classification_report(y_test, y_pred_knn))\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:246\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    244\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fit_method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ArgKminClassMode\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[0;32m    247\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\n\u001b[0;32m    248\u001b[0m     ):\n\u001b[0;32m    249\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_:\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:471\u001b[0m, in \u001b[0;36mArgKminClassMode.is_usable_for\u001b[1;34m(cls, X, Y, metric)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_usable_for\u001b[39m(\u001b[38;5;28mcls\u001b[39m, X, Y, metric) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the dispatcher can be used for the given parameters.\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m    True if the PairwiseDistancesReduction can be used, else False.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 471\u001b[0m         ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(X, Y, metric)\n\u001b[0;32m    472\u001b[0m         \u001b[38;5;66;03m# TODO: Support CSR matrices.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(X)\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(Y)\n\u001b[0;32m    475\u001b[0m         \u001b[38;5;66;03m# TODO: implement Euclidean specialization with GEMM.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqeuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    477\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:115\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for\u001b[1;34m(cls, X, Y, metric)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_sparse_matrix\u001b[39m(X):\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    103\u001b[0m         isspmatrix_csr(X)\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m         X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mint32\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    113\u001b[0m is_usable \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    114\u001b[0m     get_config()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_cython_pairwise_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (is_numpy_c_ordered(X) \u001b[38;5;129;01mor\u001b[39;00m is_valid_sparse_matrix(X))\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (is_numpy_c_ordered(Y) \u001b[38;5;129;01mor\u001b[39;00m is_valid_sparse_matrix(Y))\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mfloat32, np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_metrics()\n\u001b[0;32m    120\u001b[0m )\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_usable\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:99\u001b[0m, in \u001b[0;36mBaseDistancesReductionDispatcher.is_usable_for.<locals>.is_numpy_c_ordered\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_numpy_c_ordered\u001b[39m(X):\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflags\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Flags' object has no attribute 'c_contiguous'"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors (KNN) Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# KNN Model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"KNN Classification Report:\", classification_report(y_test, y_pred_knn))\n",
    "print(\"KNN Confusion Matrix:\", confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Improvement - Hyperparameter Tuning and Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# GridSearchCV for KNN\u001b[39;00m\n\u001b[0;32m     20\u001b[0m grid_knn \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe_knn, param_grid_knn, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m grid_knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Best parameters and score\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for KNN:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_knn\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:754\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    751\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    753\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 754\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[0;32m    755\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:813\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    811\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 813\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:266\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score(partial(_cached_call, \u001b[38;5;28;01mNone\u001b[39;00m), estimator, X, y_true, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:353\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_overlap(\n\u001b[0;32m    346\u001b[0m     message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is an overlap between set kwargs of this scorer instance and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    352\u001b[0m )\n\u001b[1;32m--> 353\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m method_caller(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, X)\n\u001b[0;32m    354\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:86\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[1;32m---> 86\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m _get_response_values(\n\u001b[0;32m     87\u001b[0m     estimator, \u001b[38;5;241m*\u001b[39margs, response_method\u001b[38;5;241m=\u001b[39mresponse_method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py:85\u001b[0m, in \u001b[0;36m_get_response_values\u001b[1;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     83\u001b[0m     pos_label \u001b[38;5;241m=\u001b[39m pos_label \u001b[38;5;28;01mif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 85\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m prediction_method(X)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:508\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    507\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:264\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    262\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 264\u001b[0m     neigh_dist, neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkneighbors(X)\n\u001b[0;32m    266\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    267\u001b[0m _y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:877\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    873\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set algorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    875\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method\n\u001b[0;32m    876\u001b[0m         )\n\u001b[1;32m--> 877\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs, prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[0;32m    878\u001b[0m         delayed(_tree_query_parallel_helper)(\n\u001b[0;32m    879\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree, X[s], n_neighbors, return_distance\n\u001b[0;32m    880\u001b[0m         )\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m gen_even_slices(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], n_jobs)\n\u001b[0;32m    882\u001b[0m     )\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal: _fit_method not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gangt\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:683\u001b[0m, in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tree_query_parallel_helper\u001b[39m(tree, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    678\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper for the Parallel calls in KNeighborsMixin.kneighbors.\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \n\u001b[0;32m    680\u001b[0m \u001b[38;5;124;03m    The Cython method tree.query is not directly picklable by cloudpickle\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;124;03m    under PyPy.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Creating a pipeline for scaling and KNN\n",
    "pipe_knn = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(weights='distance'))\n",
    "])\n",
    "\n",
    "# Extended range of n_neighbors and trying different algorithms\n",
    "param_grid_knn = {\n",
    "    'knn__n_neighbors': range(3, 20),\n",
    "    'knn__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'knn__algorithm': ['ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# GridSearchCV for KNN\n",
    "grid_knn = GridSearchCV(pipe_knn, param_grid_knn, cv=5, scoring='accuracy')\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters for KNN:\", grid_knn.best_params_)\n",
    "print(\"Best score for KNN:\", grid_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1388  470]\n",
      " [ 798  236]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.69      1858\n",
      "           1       0.33      0.23      0.27      1034\n",
      "\n",
      "    accuracy                           0.56      2892\n",
      "   macro avg       0.48      0.49      0.48      2892\n",
      "weighted avg       0.53      0.56      0.54      2892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply StandardScaler for feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# KNN model with best parameters\n",
    "knn_best = KNeighborsClassifier(n_neighbors=4, metric='manhattan', algorithm='ball_tree')\n",
    "knn_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_knn_best = knn_best.predict(X_test_scaled)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_knn_best)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, y_pred_knn_best)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bagging with KNN: 0.5304287690179806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Create a pipeline with standard scaling and KNN\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=4, algorithm='ball_tree', metric='manhattan'))\n",
    "])\n",
    "\n",
    "# Bagging ensemble of KNN\n",
    "bagging_knn = BaggingClassifier(base_estimator=knn_pipeline, n_estimators=10, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "bagging_knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = bagging_knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy of Bagging with KNN:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submisstion file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gangt\\AppData\\Local\\Temp\\ipykernel_27244\\1992231642.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output['NObeyesdad'] = y_pred\n",
      "C:\\Users\\gangt\\AppData\\Local\\Temp\\ipykernel_27244\\1992231642.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output['NObeyesdad'] = output['NObeyesdad'].map({0: 'Insufficient_Weight', 1: 'Normal_Weight', 2: 'Overweight_Level_I', 3: 'Overweight_Level_II', 4: 'Obesity_Type_I', 5: 'Obesity_Type_II', 6: 'Obesity_Type_III'})\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set using the xgb model with the best parameters\n",
    "y_pred = xgb.predict(test)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "output = test[['id']]\n",
    "output['NObeyesdad'] = y_pred\n",
    "# NObeyesdad to original values\n",
    "output['NObeyesdad'] = output['NObeyesdad'].map({0: 'Insufficient_Weight', 1: 'Normal_Weight', 2: 'Overweight_Level_I', 3: 'Overweight_Level_II', 4: 'Obesity_Type_I', 5: 'Obesity_Type_II', 6: 'Obesity_Type_III'})\n",
    "# save to csv\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
